{
    "model": "Qwen/Qwen2.5-Coder-1.5B-Instruct-AWQ",
    "disable_log_requests": true,
    "gpu_memory_utilization": 0.5,
    "pipeline_parallel_size": 1,
    "enforce_eager": true,
    "max_model_len": 4000,
    "device": "cuda:1"
}
"max_num_seqs": 4,               
"max_num_batched_tokens": 2072,  
"block_size": 16,                             
